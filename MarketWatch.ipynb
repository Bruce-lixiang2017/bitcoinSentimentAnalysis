{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk, re, string\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import wordnet\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def marketwatch_parser():\n",
    "\n",
    "    def tokenize_date(s):\n",
    "        pattern=r'[a-z{3}]+[\\.\\s]+[\\d{1,2}\\,\\s]+[\\d{4}]+'                        \n",
    "        tokens=nltk.regexp_tokenize(s, pattern)\n",
    "        date = tokens\n",
    "        return date;\n",
    "    headlines=[]\n",
    "\n",
    "    page_url= \"https://www.marketwatch.com/search?q=bitcoin&m=Keyword&rpp=500&mp=806&bd=false&bdv=&rs=false\"\n",
    "\n",
    "    while page_url!=None:\n",
    "        page = requests.get(page_url) \n",
    "\n",
    "        if page.status_code!=200:\n",
    "             page_url=None\n",
    "        else:\n",
    "            all_data = []\n",
    "\n",
    "            page_url = \"https://www.marketwatch.com/search?q=bitcoin&m=Keyword&rpp=500&mp=806&bd=false&bdv=&rs=false\"\n",
    "            page = requests.get(page_url)\n",
    "            soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "            divs = soup.find_all(\"div\", class_ = \"searchresult\")\n",
    "            titles_dictionary = []\n",
    "            for idx, div in enumerate(divs):\n",
    "                titles = div.select(\"a\")\n",
    "                if titles != []:\n",
    "                    title = titles[0].get_text().lower()\n",
    "                    titles_dictionary.append(lemmatize(title))\n",
    "            divs_dates = soup.find_all(\"div\", class_ = \"deemphasized\")\n",
    "            dates_list = []\n",
    "            for idx, div in enumerate(divs_dates):\n",
    "                date = div.get_text().lower()\n",
    "                date = str(tokenize_date(date)[0])\n",
    "                dates_list.append(date)\n",
    "            data = zip(titles_dictionary,dates_list)  \n",
    "            all_data.extend(data)\n",
    "\n",
    "        page_url = None\n",
    "\n",
    "        keywords = ['bitcoin','cryptocurrency','cryptocurrencies', 'crypto', 'blockchain']\n",
    "        filtered_data = filter(lambda x: any(word in x[0] for word in keywords), all_data)\n",
    "    return filtered_data\n",
    "# data_frame = pd.DataFrame.from_records(filtered_data, columns = [\"Tokenized Title\", \"Date\"])\n",
    "# data_frame.to_csv(\"marketwatch.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
