{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk, re, string\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import wordnet\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def get_wordnet_pos(pos_tag):\n",
    "    \n",
    "    # if pos tag starts with 'J'\n",
    "    if pos_tag.startswith('J'):\n",
    "        # return wordnet tag \"ADJ\"\n",
    "        return wordnet.ADJ\n",
    "    \n",
    "    # if pos tag starts with 'V'\n",
    "    elif pos_tag.startswith('V'):\n",
    "        # return wordnet tag \"VERB\"\n",
    "        return wordnet.VERB\n",
    "    \n",
    "    # if pos tag starts with 'N'\n",
    "    elif pos_tag.startswith('N'):\n",
    "        # return wordnet tag \"NOUN\"\n",
    "        return wordnet.NOUN\n",
    "    \n",
    "    elif pos_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        # be default, return wordnet tag \"NOUN\"\n",
    "        return wordnet.NOUN\n",
    "\n",
    "def tokenize(s):\n",
    "\n",
    "    text= s\n",
    "\n",
    "    pattern=r'[a-zA-Z]+[a-zA-Z\\-\\.]*'                        \n",
    "\n",
    "    tokens=nltk.regexp_tokenize(text, pattern)\n",
    "\n",
    "    vocabulary= tokens\n",
    "    return vocabulary;\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "headlines=[]\n",
    "    \n",
    "page_url= \"https://www.coindesk.com/category/markets-news/markets-markets-news/markets-bitcoin/\"\n",
    "\n",
    "while page_url!=None:\n",
    "    page = requests.get(page_url) \n",
    "    \n",
    "    if page.status_code!=200:\n",
    "         page_url=None\n",
    "    else:\n",
    "        all_data = []\n",
    "        for num in range(1,20):\n",
    "            page_url = \"https://www.coindesk.com/category/markets-news/markets-markets-news/markets-bitcoin/page/\"+str(num)+\"/\"\n",
    "            page = requests.get(page_url)\n",
    "            soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "            titles = soup.find_all(\"a\", class_ = \"fade\")\n",
    "            titles_list = []\n",
    "            titles_dictionary = []\n",
    "            for i in titles:\n",
    "                title = i.get_text().lower()\n",
    "                titles_list.append(title)\n",
    "                title = tokenize(title)\n",
    "                tagged_tokens = nltk.pos_tag(title)\n",
    "                le_words =[wordnet_lemmatizer.lemmatize(word, get_wordnet_pos(tag)) \\\n",
    "                           for (word, tag) in tagged_tokens \\\n",
    "                           if word not in stop_words and \\\n",
    "                           word not in string.punctuation]\n",
    "                vocabulary = set(le_words)\n",
    "                dictionary={word: title.count(word) for word in vocabulary}\n",
    "                filtered_dictionary={word: dictionary[word] for word in dictionary if word not in stop_words}\n",
    "                titles_dictionary.append(filtered_dictionary)\n",
    "            dates = soup.find_all(\"time\")\n",
    "            dates_list = []\n",
    "            for i in dates:\n",
    "                date = i.get_text().lower()\n",
    "                date = date.replace(' at', '')\n",
    "                date = datetime.strptime(date, '%b %d, %Y %H:%M')\n",
    "                date = datetime.strftime(date,'%b-%d-%Y')\n",
    "                dates_list.append(date)\n",
    "            authors = soup.find_all(\"cite\")\n",
    "            authors_list = []\n",
    "            for i in authors:\n",
    "                author = i.get_text().lower()\n",
    "                authors_list.append(author)\n",
    "            data = zip(titles_list, titles_dictionary,dates_list,authors_list)  \n",
    "            all_data.extend(data)\n",
    "    \n",
    "    page_url = None\n",
    "data_frame = pd.DataFrame.from_records(all_data, columns = [\"Title\", \"Tokenized Title\", \"Date\", \"Authors\"])\n",
    "data_frame.to_csv(\"coindesk_markets.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
